{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a128a7e5",
   "metadata": {},
   "source": [
    "# PyTorch 基础 : 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c577e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先要引入相关的包\n",
    "import torch\n",
    "import numpy as np\n",
    "#打印一下版本\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c38e9",
   "metadata": {},
   "source": [
    "张量(Tensor)\n",
    "张量的英文是Tensor，它是PyTorch里面基础的运算单位，与Numpy的ndarray相同都表示的是一个多维的矩阵。 与ndarray的最大区别就是，PyTorch的Tensor可以在 GPU 上运行，而 numpy 的 ndarray 只能在 CPU 上运行，在GPU上运行大大加快了运算速度。\n",
    "\n",
    "下面我们生成一个简单的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3a6ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1275, 0.5425, 0.0062],\n",
       "        [0.8000, 0.4086, 0.4079]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ae6f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 可以使用与numpy相同的shape属性查看\n",
    "print(x.shape)\n",
    "# 也可以使用size()函数，返回的结果都是相同的\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b69a98b",
   "metadata": {},
   "source": [
    "张量（Tensor）是一个定义在一些向量空间和一些对偶空间的笛卡儿积上的多重线性映射，其坐标是|n|维空间内，有|n|个分量的一种量， 其中每个分量都是坐标的函数， 而在坐标变换时，这些分量也依照某些规则作线性变换。r称为该张量的秩或阶（与矩阵的秩和阶均无关系）。 (来自百度百科)\n",
    "\n",
    "下面我们来生成一些多维的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb69de7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[9.7230e-01, 8.4947e-01, 5.5444e-01, 1.1629e-01, 8.3439e-01],\n",
       "          [4.7623e-01, 8.9778e-01, 7.2757e-01, 3.4862e-01, 9.2345e-01],\n",
       "          [8.2392e-03, 5.1151e-01, 8.7278e-01, 4.9283e-01, 6.6071e-01],\n",
       "          [7.8230e-01, 7.5169e-01, 1.3563e-02, 5.4069e-01, 3.9481e-01]],\n",
       "\n",
       "         [[8.3231e-01, 7.8936e-02, 2.6949e-01, 9.4202e-02, 5.2813e-02],\n",
       "          [4.1217e-01, 9.1109e-01, 3.5115e-02, 4.9986e-01, 4.5717e-01],\n",
       "          [3.5710e-01, 3.5371e-01, 2.9014e-01, 4.3921e-01, 3.4224e-01],\n",
       "          [7.4683e-01, 4.5477e-01, 5.1109e-02, 5.9573e-01, 6.3002e-01]],\n",
       "\n",
       "         [[1.2617e-01, 8.6604e-01, 3.9610e-01, 2.0929e-01, 1.1134e-01],\n",
       "          [4.4782e-01, 7.6718e-01, 6.3862e-01, 1.8258e-02, 6.8985e-01],\n",
       "          [6.7836e-02, 9.4923e-02, 8.1621e-01, 8.2220e-01, 8.9897e-01],\n",
       "          [7.9946e-01, 8.4266e-01, 1.0589e-01, 8.0874e-01, 6.9847e-01]]],\n",
       "\n",
       "\n",
       "        [[[3.5114e-01, 1.9503e-01, 9.1268e-02, 9.2107e-01, 3.9193e-01],\n",
       "          [7.9013e-01, 4.2648e-01, 8.7963e-01, 8.4726e-01, 1.8357e-02],\n",
       "          [3.2986e-01, 3.4963e-01, 1.5034e-01, 8.0936e-01, 8.2035e-02],\n",
       "          [5.4530e-02, 2.6294e-01, 4.0696e-02, 7.8252e-01, 2.0439e-01]],\n",
       "\n",
       "         [[6.3845e-02, 3.5939e-01, 3.9039e-01, 4.4037e-01, 4.7523e-01],\n",
       "          [4.3712e-01, 4.4332e-01, 3.4276e-01, 7.6698e-01, 8.7685e-01],\n",
       "          [1.1124e-02, 8.0766e-01, 5.7456e-01, 1.6799e-02, 5.6925e-01],\n",
       "          [8.3149e-01, 4.2421e-01, 8.5342e-01, 6.7592e-01, 4.1285e-01]],\n",
       "\n",
       "         [[3.6529e-01, 3.9682e-01, 7.4310e-01, 2.8135e-01, 4.4958e-02],\n",
       "          [5.8733e-01, 6.8322e-01, 1.4009e-02, 5.7503e-01, 6.0743e-01],\n",
       "          [9.5452e-01, 7.5530e-02, 9.2248e-02, 6.4766e-01, 4.8035e-01],\n",
       "          [6.5746e-01, 4.0286e-01, 3.4201e-04, 1.0908e-01, 7.1495e-01]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(2, 3, 4, 5)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c75d4",
   "metadata": {},
   "source": [
    "在同构的意义下，第零阶张量 （r = 0） 为标量 （Scalar），第一阶张量 （r = 1） 为向量 （Vector）， 第二阶张量 （r = 2） 则成为矩阵 （Matrix），第三阶以上的统称为多维张量。\n",
    "\n",
    "其中要特别注意的就是标量，我们先生成一个标量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7de5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我们直接使用现有数字生成\n",
    "scalar =torch.tensor(3.14)\n",
    "print(scalar)\n",
    "#打印标量的大小\n",
    "scalar.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe7a2e",
   "metadata": {},
   "source": [
    "对于标量，我们可以直接使用 .item() 从中取出其对应的python对象的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94eecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.140000104904175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef367b",
   "metadata": {},
   "source": [
    "特别的：如果张量中只有一个元素的tensor也可以调用tensor.item方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd78020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([3.14])\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eab05ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.140000104904175"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c90773",
   "metadata": {},
   "source": [
    "基本类型\n",
    "Tensor的基本数据类型有五种：\n",
    "\n",
    "32位浮点型：torch.FloatTensor。 (默认)\n",
    "\n",
    "64位整型：torch.LongTensor。\n",
    "\n",
    "32位整型：torch.IntTensor。\n",
    "\n",
    "16位整型：torch.ShortTensor。\n",
    "\n",
    "64位浮点型：torch.DoubleTensor。\n",
    "\n",
    "除以上数字类型外，还有 byte和chart型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad2cf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = tensor.long()\n",
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eec8233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1406], dtype=torch.float16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half=tensor.half()\n",
    "half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8182fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_t=tensor.int()\n",
    "int_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece9fc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1400])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flo = tensor.float()\n",
    "flo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f408e170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], dtype=torch.int16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short = tensor.short()\n",
    "short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997def94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], dtype=torch.int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = tensor.char()\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723c30e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt = tensor.byte()\n",
    "bt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4785ba0",
   "metadata": {},
   "source": [
    "## Numpy转换\n",
    "使用numpy方法将Tensor转为ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8314111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.594051  ,  0.14808884],\n",
       "       [-1.3971018 ,  0.31728458],\n",
       "       [-0.33503816,  0.64477617]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((3, 2))\n",
    "# tensor转化为numpy\n",
    "numpy_a = a.numpy()\n",
    "numpy_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f4121",
   "metadata": {},
   "source": [
    "numpy转化为Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "065cf66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5941,  0.1481],\n",
       "        [-1.3971,  0.3173],\n",
       "        [-0.3350,  0.6448]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a = torch.from_numpy(numpy_a)\n",
    "torch_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c090e6",
   "metadata": {},
   "source": [
    "*Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972ca22",
   "metadata": {},
   "source": [
    "## 设备间转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9487e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_a = torch.rand(4, 3)\n",
    "cpu_a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd36c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.mps.FloatTensor'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用torch.backends.mps.is_available()来确定是否有mps设备\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#将tensor传送到设备\n",
    "gpu_b=cpu_a.to(device)\n",
    "gpu_b.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c11c255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用torch.cuda.is_available()来确定是否有cuda设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#将tensor传送到设备\n",
    "gpu_b=cpu_a.to(device)\n",
    "gpu_b.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186ca26",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "Pytorch中有许多默认的初始化方法可以使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39ac39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.6339, 0.1056],\n",
       "        [0.4796, 0.7719, 0.5995],\n",
       "        [0.2394, 0.3644, 0.0045],\n",
       "        [0.5110, 0.7497, 0.0582],\n",
       "        [0.3917, 0.9368, 0.7134]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "rnd = torch.rand(5, 3)\n",
    "rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab99dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化，使用1填充\n",
    "one = torch.ones(2, 2)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5d7e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化，使用0填充\n",
    "zero=torch.zeros(2,2)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4af171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#初始化一个单位矩阵，即对角线为1 其他为0\n",
    "eye=torch.eye(4, 4)\n",
    "eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753471d",
   "metadata": {},
   "source": [
    "## 常用方法\n",
    "PyTorch中对张量的操作api 和 NumPy 非常相似，如果熟悉 NumPy 中的操作，那么他们二者基本是一致的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aab3f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7840, -0.1361, -1.5207],\n",
      "        [ 1.8314, -0.9056, -0.1304],\n",
      "        [ 0.6368,  0.2849, -0.0514]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfec2735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1361,  1.8314,  0.6368]) tensor([1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 沿着行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e0f2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.8314,  0.2849, -0.0514]) tensor([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 沿着列取最大值\n",
    "max_value, max_idx = torch.max(x, dim=0)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c2da630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4408,  0.7954,  0.8704])\n"
     ]
    }
   ],
   "source": [
    "# 每行 x 求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef577d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7954, -1.0313, -1.9906],\n",
      "        [ 3.1696, -0.1007,  0.8009],\n",
      "        [ 1.2387,  0.4417,  0.7696]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.randn(3, 3)\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eef656",
   "metadata": {},
   "source": [
    "以_为结尾的，均会改变调用值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "098f27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7954, -1.0313, -1.9906],\n",
      "        [ 3.1696, -0.1007,  0.8009],\n",
      "        [ 1.2387,  0.4417,  0.7696]])\n"
     ]
    }
   ],
   "source": [
    "# add 完成后x的值改变了\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
